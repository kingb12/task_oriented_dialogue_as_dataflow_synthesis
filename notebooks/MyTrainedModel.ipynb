{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648cac15",
   "metadata": {},
   "source": [
    "# Replication of SMCalFlow Experiments on V2 Dataset\n",
    "\n",
    "This notebook explores some of the output from an ONMT model trained on the v2 version of the dataflow dialogues dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554574c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflow.core.lispress import *\n",
    "from dataflow.core.linearize import *\n",
    "from typeguard import check_type\n",
    "import json\n",
    "from pprint import pprint\n",
    "from onmt.bin.translate import translate\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4949e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onmt_translate --model /scratchdata/bking2/tod_as_df_synthesis/output/onmt_models_v2/checkpoint_step_9130.pt --max_length 491 --src /tmp/utterance.src_tok --replace_unk --n_best 1 --batch_size 8 --beam_size 10 --gpu 1 --report_time --output /tmp/out.nbest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-10 11:06:24,208 INFO] Translating shard 0.\n",
      "/soe/bking2/task_oriented_dialogue_as_dataflow_synthesis/venv/lib/python3.7/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED AVG SCORE: -0.0147, PRED PPL: 1.0148\n",
      "Total translation time (s): 0.214429\n",
      "Average translation time (s): 0.214429\n",
      "Tokens per second: 158.560539\n",
      "(Yield\n",
      "  (singleton\n",
      "    (QueryEventResponse.results\n",
      "      (FindEventWrapperWithDefaults\n",
      "        (Event.attendees_?\n",
      "          (AttendeeListHasRecipientConstraint\n",
      "            (RecipientWithNameLike\n",
      "              (^(Recipient) EmptyStructConstraint)\n",
      "              (PersonName.apply \" janice \"))))))))\n",
      "(Yield\n",
      "  (Event.id\n",
      "    (singleton\n",
      "      (QueryEventResponse.results\n",
      "        (FindEventWrapperWithDefaults\n",
      "          (Event.attendees_?\n",
      "            (AttendeeListHasRecipientConstraint\n",
      "              (RecipientWithNameLike\n",
      "                (^(Recipient) EmptyStructConstraint)\n",
      "                (PersonName.apply \"janice kang\")))))))))\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = \"/scratchdata/bking2/tod_as_df_synthesis/output/onmt_models_v2/checkpoint_step_9130.pt\"\n",
    "def simple_infer(utterance: str) -> str:\n",
    "    options = {\"model\": best_checkpoint, \n",
    "           \"max_length\": 491, \"src\": \"../output/onmt_text_data/valid.src_tok\",\n",
    "           \"replace_unk\": True, \"n_best\": 1, \n",
    "           \"batch_size\": 8, \"beam_size\": 10, \"gpu\": 1, \"report_time\": True, \n",
    "           \"output\": \"/tmp/out.nbest\"}\n",
    "    with open(\"/tmp/out.nbest\", \"w\") as f:\n",
    "        # clear result first\n",
    "        f.truncate(0)\n",
    "    with open(\"/tmp/utterance.src_tok\", \"w\") as f:\n",
    "        f.write(utterance)\n",
    "    options['src'] = \"/tmp/utterance.src_tok\"\n",
    "    call: List[str] = [\"onmt_translate\"]\n",
    "    for k, v in options.items():\n",
    "        call.extend([(\"--\" + k), str(v)])\n",
    "        if type(v) == bool:\n",
    "            call.pop() # boolean arguments are just flags, no value for them\n",
    "    print(\" \".join(call))\n",
    "    subprocess.call(call)\n",
    "    with open(\"/tmp/out.nbest\", \"r\") as f:\n",
    "        return parse_lispress(f.read())\n",
    "print(render_pretty(simple_infer(\"what is my appointment with janice kang\")))\n",
    "\n",
    "lisp_str: str = \"\"\"(Yield\n",
    "  (Event.id\n",
    "    (singleton\n",
    "      (QueryEventResponse.results\n",
    "        (FindEventWrapperWithDefaults\n",
    "          (Event.attendees_?\n",
    "            (AttendeeListHasRecipientConstraint\n",
    "              (RecipientWithNameLike\n",
    "                (^(Recipient) EmptyStructConstraint)\n",
    "                (PersonName.apply \"janice kang\")))))))))\n",
    "\"\"\"\n",
    "lispress = parse_lispress(lisp_str)\n",
    "\n",
    "\n",
    "print(render_pretty(lispress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616d01c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onmt_translate --model /scratchdata/bking2/tod_as_df_synthesis/output/onmt_models_v2/checkpoint_step_9130.pt --max_length 491 --src /tmp/utterance.src_tok --replace_unk --n_best 1 --batch_size 8 --beam_size 10 --gpu 1 --report_time --output /tmp/out.nbest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-10 11:06:29,052 INFO] Translating shard 0.\n",
      "/soe/bking2/task_oriented_dialogue_as_dataflow_synthesis/venv/lib/python3.7/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED AVG SCORE: -0.0038, PRED PPL: 1.0038\n",
      "Total translation time (s): 0.408814\n",
      "Average translation time (s): 0.408814\n",
      "Tokens per second: 166.334831\n",
      "(Yield\n",
      "  (CreateCommitEventWrapper\n",
      "    (CreatePreflightEventWrapper\n",
      "      (&\n",
      "        (&\n",
      "          (Event.subject_? (?= \" discuss status \"))\n",
      "          (Event.start_? (DateTimeConstraint (Afternoon) (Today))))\n",
      "        (Event.attendees_?\n",
      "          (AttendeeListHasRecipient\n",
      "            (Execute\n",
      "              (refer\n",
      "                (extensionConstraint\n",
      "                  (RecipientWithNameLike\n",
      "                    (^(Recipient) EmptyStructConstraint)\n",
      "                    (PersonName.apply \" Matt \")))))))))))\n"
     ]
    }
   ],
   "source": [
    "simple = \"Can you book a meeting at 3pm this afternoon with Matt to discuss status ?\"\n",
    "my_prediction = \"\"\"\n",
    "(Yield\n",
    "  (CreateCommitEventWrapper\n",
    "    (CreatePreflightEventWrapper\n",
    "      (&\n",
    "        (Event.start_? (?= (NextTime (NumberPM 3L))))\n",
    "        (Event.name_? (?= \"discuss status\"))\n",
    "        (Event.attendees_?\n",
    "          (AttendeeListHasRecipient\n",
    "            (Execute\n",
    "              (refer\n",
    "                (extensionConstraint\n",
    "                  (RecipientWithNameLike\n",
    "                    (^(Recipient) EmptyStructConstraint)\n",
    "                    (PersonName.apply \"Matt\")))))))))))\n",
    "\"\"\"\n",
    "print(render_pretty(simple_infer(simple)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99691e38",
   "metadata": {},
   "source": [
    "## Results in Brief\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1003dbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ignoringRefer': {'accuracy': 0.7276229994072317,\n",
      "                   'ave_num_turns_before_first_error': 1.757462686567164,\n",
      "                   'num_correct_dialogues': 1262,\n",
      "                   'num_correct_turns': 9820,\n",
      "                   'num_total_dialogues': 3484,\n",
      "                   'num_total_turns': 13496,\n",
      "                   'num_turns_before_first_error': 6123,\n",
      "                   'pct_correct_dialogues': 0.3622273249138921},\n",
      " 'notIgnoringRefer': {'accuracy': 0.7058387670420866,\n",
      "                      'ave_num_turns_before_first_error': 1.68398392652124,\n",
      "                      'num_correct_dialogues': 1183,\n",
      "                      'num_correct_turns': 9526,\n",
      "                      'num_total_dialogues': 3484,\n",
      "                      'num_total_turns': 13496,\n",
      "                      'num_turns_before_first_error': 5867,\n",
      "                      'pct_correct_dialogues': 0.33955223880597013}}\n"
     ]
    }
   ],
   "source": [
    "with open('../output/evaluation_output_v2/valid.all.scores.json', 'r') as f:\n",
    "    results = json.loads(f.read())\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8ffb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
